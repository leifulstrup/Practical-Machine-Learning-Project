---
title: "Practical-Machine-Learning-July-2014-LeifUlstrup.Rmd"
author: "Leif Ulstrup"
date: "July 24, 2014"
output: html_document
---
##Executive Summary

The purpose of this project is to demonstrate the analysis and model building process of machine learning tools and techniques.  The subject of this analysis and modeling exercise is a set of experimental data gathered from Brazilian university research team that have instrumented six test subjects with various motion sensors while they perform an exercise with a barbell using five techniques that range "perfect form" (A) to "very poor form" (E).  The question these researchers are exploring is whether machine learning techniques can be used on the data they collected to predict whether a person is using proper form in their exercise or not.  The ultimate vision of the team is to provide real-time feedback to those performing exercises to improve the quality of their exercise experience.

The results of the modeling below confirm that this is possible with high accuracy.  

##Context

The details of the experiment can be found here along with their research paper: 
http://groupware.les.inf.puc-rio.br/har (see section "Weight Lifting Exercises Dataset"").  See this paper: http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201.  

The A,B,C,D,E barbell lifting form type model is described in this excerpt from their paper:
"...Participants were asked to perform one set of 10 repetitions
of the Unilateral Dumbbell Biceps Curl in Five different fashions:
exactly according to the specification (Class A), throwing
the elbows to the front (Class B), lifting the dumbbell
only halfway (Class C), lowering the dumbbell only halfway
(Class D) and throwing the hips to the front (Class E). Class
A corresponds to the specified execution of the exercise,
while the other 4 classes correspond to common mistakes..."

##Model Development

###How the Model was Built

The project source data for this project consists of two data sets.  One set ("trainingFile") contains 19622 observations with 160 variables (columns in the matrix).  The test ("testFile") set contains 20 observations and also 160 variables.

The initial steps included studying the data in the training and test files through visual inspection of the files using head() and names() to get my bearings for further analysis.  I then used the nearZeroVar() function on the two sets of data.  What I discovered is that the trainFile had 60 of 160 columns reporting ner zero values (NZV) and the test file had 101 of 160 with NZV.  I also saw that the last column of the files noted the type of workout classifer ("classe") and that the first 7 columns of the file included information about the test subject, time of the test etc. that did not seem useful for the nature of this modeling (though may be useful in terms of analyzing the quality of the training inputs and the test subjects) and I exlcuded those from the data sets as part of the clean up process.

Since the testFile only used 101 columns of test inputs, I chose to immediately use that information to narrow the trainFile to the same set of columns and cleaned up both data sets so that only the same 53 columns where in use (53 = 160-100-7).  I now had two smaller data files to work with ("trainingClean" and "testClean").  

Important processing note:  I also later discovered I had to apply the as.numeric() function to the numeric input fields and the factor() function to the "$classe" column due to errors that I got in the later stages using the machine learning processing tools.  Finding the root cause of this processing problem and fix was very time consuming.  

###How Cross-validation was Used

The next step I followed in the machine learning model development process ("study design" and "cross-validation") was use of the createDataPartition() function from the caret package to randomly sample the trainingClean file and create a subset (70% of the total) for training purposes and another set for testing of the training (30%).  I now had two data sets that I could use for machine learning model development - one for training and one reference set for testing the effectiveness of the model (prior to application to eventual application to the testClean set).

###Expected Sample Error Calculations

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1667    2    3    1    1
         B   27 1088   23    0    1
         C    0   14 1003    9    0
         D    3    1   37  921    2
         E    0    2   10   10 1060

Overall Statistics
                                         
               Accuracy : 0.9752         
                 95% CI : (0.9709, 0.979)
    No Information Rate : 0.2884         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.9686         
 Mcnemar's Test P-Value : 1.242e-09      

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9823   0.9828   0.9322   0.9787   0.9962
Specificity            0.9983   0.9893   0.9952   0.9913   0.9954
Pos Pred Value         0.9958   0.9552   0.9776   0.9554   0.9797
Neg Pred Value         0.9929   0.9960   0.9850   0.9959   0.9992
Prevalence             0.2884   0.1881   0.1828   0.1599   0.1808
Detection Rate         0.2833   0.1849   0.1704   0.1565   0.1801
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9903   0.9861   0.9637   0.9850   0.9958

###Reasoning Behind Choices Made

###Link to Predictions



###R Code

```{r loadLibraries, echo=FALSE}
require(caret)

install.packages("doMC") # install parallel processing library
require(doMC)
registerDoMC(cores = 4)

require("randomForest") # for model training builds

```

```{r ingestData, echo=FALSE}

#assume that the working directory has been set correctly
#download source files to current working directory
# commented out for this effort since they are already downloaded (remove otherwise to test)
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", method="curl")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv", method="curl")
if(!("pml-testing.csv" %in% list.files())) stop("Code Stopped: Missing testing.csv file")
if(!("pml-training.csv" %in% list.files())) stop("Code Stopped: Missing testing.csv file")

#test files are in the directory

trainingFile <- read.csv("pml-training.csv") # source file for training and testing fit
testFile <- read.csv("pml-testing.csv") # ultimate test file for project submission

```

```{r dataCleanup, echo=FALSE}
# remove nearZero Values and NAs

trainingNZVCount <- length(nearZeroVar(trainingFile))
testNZVCount <- length(nearZeroVar(testFile))

# match the columns in the training source to those used in the test set
keepcols <- c()
for (i in names(testFile)) {
  if(!is.na(testFile[[i]][1])){
    #print(paste(i, "is NOT NA"))
    keepcols <- c(keepcols, i)
    }
  }

trainingClean <- data.frame()
trainingClean <- trainingFile[, (names(trainingFile) %in% keepcols)]
trainingClean$classe <- trainingFile$classe # indicator of how well the bar bell movement is performed on a scale of A to E

testClean <- data.frame()
testClean <- testFile[, (names(trainingFile) %in% keepcols)]
testClean$problem_id <- testFile$problem_id # note that the last column is "problem_id" instead of "classe"

trainingClean <- trainingClean[-c(1:7)] #remove the names, timestamp etc columns
testClean <- testClean[-c(1:7)] #remove the names, timestamp etc columns

#convert to "numeric" class except for the classe factor
for (i in 1:(length(trainingClean)-1)) {trainingClean[[i]] <- as.numeric(trainingClean[[i]])}
for (i in 1:(length(testClean)-1)) {testClean[[i]] <- as.numeric(testClean[[i]])}

```

```{r createTrainingandTest, echo=FALSE}

inTrain <- createDataPartition(y=trainingClean$classe, p=0.7, list=FALSE) # Note use of "clean" version of trainingFile
training <- trainingClean[inTrain,] # Note use of "clean" version of trainingFile
testing <- trainingClean[-inTrain,] # Note use of "clean" version of trainingFile

# !!! huge roadblock solved - another clean up item (per Class Forum post)
#  see this stackoverflow discussion:
# http://stackoverflow.com/questions/13495041/random-forests-in-r-empty-classes-in-y-and-argument-legth-0
training$classe <- factor(training$classe) #key cleanup actvity
testing$classe <- factor(testing$classe) #key cleanup actvity

# we are now set up with a set of data we can train and test our models on...let's try some models

```

```{r analyzeCorrelations, echo=FALSE}

trainingCor <- cor(training[, -length(training)]) # account for the classe factor on last column
highCor <- sum(abs(training[upper.tri(trainingCor)]) > 0.999)

highlyCor <- findCorrelation(training[, -length(training)], cutoff = 0.75)

preProc <- preProcess(training[, -length(training)], method= c("center", "scale"))

trainPredict <- predict(preProc, newdata = training[, -length(training)])

```

```{r modeling, echo=FALSE}
set.seed(12345)

# let's try a model using 

preProc <- preProcess(training[,-53], method="pca") # "-53" removes the $classe factor element
trainPC <- predict(preProc, training[,-53]) # note again extraction of $classe
modelFit <- train(training$classe ~ ., method="rf", data=trainPC) # strange construct, rf for RandomForest
print(modelFit)
testPC <- predict(preProc, testing[,-53])
confusionMatrix(testing$classe, predict(modelFit, testPC))

# Now, let's test this on the testClean data that came from the testing file
# that file as 53 cols and 20 rows and the results of that feed into the HW assignment
classTestPC <- predict(preProc, testClean[,-53]) # remove $problem_id = $classe
classTestPredictedValues <- predict(modelFit, classTestPC) # vector of predicted factors A-E
classTestPredictedValues <- as.character(classTestPredictedValues)

# code from Prediction Assignment Submission: Instructions
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
  }
pml_write_files(classTestPredictedValues) # this wites out the 20 answers to 20 files for individual upload
  
```
